# #detect_simple.py
# import tensorflow as tf
# import core.utils as utils
# from tensorflow.python.saved_model import tag_constants
# import cv2
# import numpy as np

# MODEL_PATH = './checkpoints/yolov4-416'
# IOU_THRESHOLD = 0.45
# SCORE_THRESHOLD = 0.25
# INPUT_SIZE = 416

# # load model
# saved_model_loaded = tf.saved_model.load(MODEL_PATH, tags=[tag_constants.SERVING])
# infer = saved_model_loaded.signatures['serving_default']

# def main(img_path):
#     img = cv2.imread(img_path)
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#     img_input = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))
#     img_input = img_input / 255.
#     img_input = img_input[np.newaxis, ...].astype(np.float32)
#     img_input = tf.constant(img_input)

#     pred_bbox = infer(img_input)

#     for key, value in pred_bbox.items():
#         boxes = value[:, :, 0:4]
#         pred_conf = value[:, :, 4:]

#     boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(
#         boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),
#         scores=tf.reshape(
#             pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),
#         max_output_size_per_class=50,
#         max_total_size=50,
#         iou_threshold=IOU_THRESHOLD,
#         score_threshold=SCORE_THRESHOLD
#     )

#     pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]
#     result = utils.draw_bbox(img, pred_bbox)

#     result = cv2.cvtColor(np.array(result), cv2.COLOR_RGB2BGR)
#     cv2.imwrite('result.png', result)

# if __name__ == '__main__':
#     img_path = './data/kite.jpg'
#     main(img_path)

#============================================================================================
#네이버 퍼옴

import cv2
from tracker import *

# Create tracker object
tracker = EuclideanDistTracker()

cap = cv2.VideoCapture("highway.mp4")

# Object detection from Stable camera
object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)

while True:
    ret, frame = cap.read()
    height, width, _ = frame.shape

    # Extract Region of interest
    roi = frame[340: 720,500: 800]

    # 1. Object Detection
    mask = object_detector.apply(roi)
    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    detections = []
    for cnt in contours:
        # Calculate area and remove small elements
        area = cv2.contourArea(cnt)
        if area > 100:
            #cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)
            x, y, w, h = cv2.boundingRect(cnt)


            detections.append([x, y, w, h])

    # 2. Object Tracking
    boxes_ids = tracker.update(detections)
    for box_id in boxes_ids:
        x, y, w, h, id = box_id
        cv2.putText(roi, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)
        cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)

    cv2.imshow("roi", roi)
    cv2.imshow("Frame", frame)
    cv2.imshow("Mask", mask)

    key = cv2.waitKey(30)
    if key == 27:
        break
